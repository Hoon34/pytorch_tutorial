{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 numpy의 array랑 똑같다고 생각하면 된다. 다른 점은 텐서는 GPU로의 연산이 가능해 계산을 가속할 수 있다. 우리는 이 텐서를 모델의 input, output 그리고 parameter로 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor initializaiton\n",
    "텐서는 다양한 방법으로 만들 수 있는데 첫번째는 데이터(List, array)를 직접 가져오는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "tensor = torch.tensor(data)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "array = np.array(data)\n",
    "tensor = torch.tensor(array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째는 넘파이와 같이 특정 숫자의 element들을 가지는 tensor을 만들 수 있다.\n",
    "like 애들은 텐서를 넣어주면 같은 size를 가진 텐서를 반환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "t_ones = torch.ones_like(tensor)  ## 텐서를 넣고 해당 텐서와 같은 size를 가진 텐서를 반환\n",
    "print(t_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1375, 0.0834],\n",
      "        [0.1737, 0.5616]])\n"
     ]
    }
   ],
   "source": [
    "t_rand = torch.rand_like(tensor, dtype=torch.float)  ## [0,1)의 random sample을 반환\n",
    "print(t_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size만 넣어줘서 특정 형태의 텐서를 만들어주는 것은 넘파이랑 똑같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9250, 0.5985, 0.5122],\n",
      "        [0.7285, 0.7026, 0.7047]]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "size = (2,3)\n",
    "\n",
    "random_tensor = torch.rand(size)\n",
    "one_tensor = torch.ones(size)\n",
    "zero_tensor = torch.zeros(size)\n",
    "print( random_tensor,\"\\n\", one_tensor, \"\\n\",zero_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Attributes\n",
    "텐서들의 attributes를 파악해 텐서의 사이즈, dtype, device를 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros((2,2))\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operation\n",
    "\n",
    "텐서에 수많은 operation들이 가능하다. 먼저 텐서 연산들을 빠르게 하기 위해 이를 GPU로 보내면 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy array와 같이 텐서를 indexing 및 slicing이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 cat 함수를 통해 concat할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.]]) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor], dim=1)\n",
    "t2 = torch.cat([tensor, tensor], dim=0)\n",
    "print(t1,'\\n',t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서간의 element-wise 곱연산은 두가지 방법으로 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.mul(tensor))\n",
    "print(tensor*tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dot-product는 넘파이랑 똑같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]])\n",
      "tensor([[3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.matmul(tensor))\n",
    "print(tensor@tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수 자체를 바꾸는 inplace operator가 존재한다. Inplace operator는 memory save측면에서 도움이 되지만 history가 사라진다는 점에서 잘 쓰이진 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.add_(5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
